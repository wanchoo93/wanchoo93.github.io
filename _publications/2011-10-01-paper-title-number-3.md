---
title: "Cross-modal Map Learning for Vision and Language Navigation"
collection: publications
permalink: 
excerpt: 'This paper proposes a cross-modal map learning model for vision-and-language navigation that first learns to predict the top-down semantics on an egocentric map for both observed and unobserved regions, and then predicts a path towards the goal as a set of way-points.'
date: 2022-03-02
venue: 'CVPR'

---

Authors: Georgios Georgakis, Karl Schmeckpeper, Karan Wanchoo, Soham Dan, Eleni Miltsakaki, Dan Roth, Kostas Daniilidis

You can read more about the paper [here](https://arxiv.org/abs/2203.05137)
