---
title: "Cross-modal Map Learning for Vision and Language Navigation"
collection: publications
permalink: 
excerpt: 'This paper proposes a cross-modal map learning model for vision-and-language navigation that first learns to predict the top-down semantics on an egocentric map for both observed and unobserved regions, and then predicts a path towards the goal as a set of way-points.'
date: 2021-12-15
venue: 'submitted to CVPR-2022 (under review)'

---

Authors: Georgios Georgakis, Karan Wanchoo, Karl Schmeckpeper, Soham Dan, Eleni Miltsakaki, Kostas Daniilidis

**Accepted to CVPR - 2022. I'll be posting the link to the paper soon!!!**

You can read more about the project [here](https://wanchoo93.github.io/teaching/2017-spring-teaching-4)
